{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5634,"status":"ok","timestamp":1717358737152,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"lSqzFDtX6vgM","outputId":"16c5da00-e6c7-4bd2-f82d-d7acb471e67d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: scipy\u003e=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas) (1.16.0)\n"]}],"source":["!pip install pandas scikit-learn lightgbm\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2853,"status":"ok","timestamp":1717358739998,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"dO8K6hY-6y1B"},"outputs":[],"source":["from google.colab import drive\n","\n","import pandas as pd\n","from sklearn.model_selection import cross_val_predict, StratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import lightgbm as lgb\n","import re\n","import string\n","from sklearn.model_selection import cross_val_predict, StratifiedKFold, GridSearchCV"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46206,"status":"ok","timestamp":1717358786197,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"2cTCfx03619U","outputId":"2c45e47c-cccc-4a9b-e50a-e3f43031f2cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1717358786198,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"5IpDgzE164lf","outputId":"c9b3562d-9b4b-4034-be73-bf177031a902"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Cs412/project_files\n"]}],"source":["%cd drive/MyDrive/Cs412/project_files"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1717358786198,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"ADfw6_5u65bs","outputId":"17af410b-4365-484c-9a2d-ccecd4de2267"},"outputs":[{"name":"stdout","output_type":"stream","text":[" bugs-test.csv                       randomforest_predictions_2.csv           submission_0_51.csv\n"," bugs-train.csv                      random_forest_smote_model.pkl            submission_0_55.csv\n"," lgbm_p-_sm-.ipynb                   random_forest_smote_model_v1_0.pkl       submission.csv\n"," ngram_vectorizer.pkl                random_forest_smote_model_v2_tfidf.pkl   tfidf_vectorizer.pkl\n","'predictions_02 06 2024_02_49.csv'   \u001b[0m\u001b[01;34mresults\u001b[0m/                                 train_prep.csv\n"," predictions.csv                    'submission_02 06 2024.csv'\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":484,"status":"ok","timestamp":1717358786673,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"CwJK4JmmQUMB"},"outputs":[],"source":["def clean_text(text):\n","    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","    and remove words containing numbers'''\n","    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","    text = re.sub('\u003c.*?\u003e+', '', text)\n","    text = re.sub('\\n', '', text)\n","    return \"\".join(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tss_AhQGUuVq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1531,"status":"ok","timestamp":1717358788196,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"tdhSd4av68ih"},"outputs":[],"source":["\n","# Load the data\n","train_data = pd.read_csv('bugs-train.csv')\n","test_data = pd.read_csv('bugs-test.csv')\n","# Prepare the data\n","X = train_data['summary']\n","test_data['summary'] = test_data['summary']\n","y = train_data['severity']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1W3bANrMRxJFjEpwQnCrkDDOFXqm3mVBf"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717354960363,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"CnjRCRkKUvZ2","outputId":"d38c9911-49dc-4bad-a475-c9473bee03fe"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["output_file_path = 'train_prep.csv'\n","train_data.to_csv(output_file_path,index=False)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1659,"status":"ok","timestamp":1717358792190,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"5EPwQDWuKRgg"},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Convert text data to TF-IDF features\n","tfidf = TfidfVectorizer()\n","X_tfidf = tfidf.fit_transform(X)\n","# Encode the severity labels using LabelEncoder\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(y)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5908,"status":"ok","timestamp":1717355293583,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"XSDH3hD8WgTN","outputId":"df09c354-ccb2-4521-c553-ad7344f69b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"]}],"source":["!pip install tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"iQMCpTd_V-4Y"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"]}],"source":["from tqdm import tqdm\n","from sklearn.metrics import classification_report, make_scorer, precision_score\n","# Define the parameter grid\n","param_grid = {\n","    'num_leaves': [31, 50],\n","    'max_depth': [-1, 10, 20],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'n_estimators': [100, 200]\n","}\n","scorer = make_scorer(precision_score, average='macro')\n","\n","model = lgb.LGBMClassifier(n_jobs=-1, verbose = 3)\n","# Stratified 5-fold cross-validation with grid search\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring=scorer, n_jobs=-1, verbose=3)\n","\n","# Fit the grid search\n","grid_search.fit(X_tfidf, y_encoded)\n","\n","# Print best parameters and best score\n","print(\"Best parameters found: \", grid_search.best_params_)\n","print(\"Best cross-validation score: \", grid_search.best_score_)\n","\n","# Predict using the best estimator\n","best_model = grid_search.best_estimator_\n","# Stratified 5-fold cross-validation with progress tracking\n","predictions = []\n","for train_index, test_index in tqdm(cv.split(X_tfidf, y_encoded), total=cv.get_n_splits()):\n","    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n","    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n","\n","    best_model.fit(X_train, y_train)\n","    y_pred = best_model.predict(X_test)\n","    predictions.extend(y_pred)\n","\n","    print(f\"Classification Report for current fold:\")\n","    print(classification_report(y_test, y_pred))\n","\n","# Overall classification report\n","predictions = np.array(predictions)\n","print(\"Overall Classification Report:\")\n","print(classification_report(y_encoded, predictions))\n","\n","# Train the final model on the full training set and predict on the test set\n","best_model.fit(X_tfidf, y_encoded)\n","test_tfidf = tfidf.transform(test_data['summary'])\n","test_predictions = best_model.predict(test_tfidf)\n","\n","# Map the predictions back to their string values\n","test_data['severity_mapped'] = test_predictions\n","test_data['severity'] = le.inverse_transform(test_data['severity_mapped'])\n","\n","# Prepare the output data\n","test_data.rename(columns={\"bug id\": \"bug_id\"}, inplace=True)\n","output_data = test_data[['bug_id', 'severity']]\n","output_file_path = 'randomforest_predictions_2.csv'\n","output_data.to_csv(output_file_path, index=False)\n","\n","print(f\"Predictions saved to {output_file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324160,"status":"ok","timestamp":1717354527861,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"1mMJg-hi6mtf","outputId":"70282288-a05c-4f50-a8cd-b239babe6507"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.689394 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217497\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4703\n","[LightGBM] [Info] Start training from score -5.430049\n","[LightGBM] [Info] Start training from score -2.148910\n","[LightGBM] [Info] Start training from score -3.587888\n","[LightGBM] [Info] Start training from score -3.274480\n","[LightGBM] [Info] Start training from score -3.942950\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.889717\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.479712 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217559\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4705\n","[LightGBM] [Info] Start training from score -5.431833\n","[LightGBM] [Info] Start training from score -2.148910\n","[LightGBM] [Info] Start training from score -3.587605\n","[LightGBM] [Info] Start training from score -3.274480\n","[LightGBM] [Info] Start training from score -3.943353\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.888679\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.698097 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 217526\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4711\n","[LightGBM] [Info] Start training from score -5.430049\n","[LightGBM] [Info] Start training from score -2.148843\n","[LightGBM] [Info] Start training from score -3.587605\n","[LightGBM] [Info] Start training from score -3.274687\n","[LightGBM] [Info] Start training from score -3.943353\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.889717\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.690275 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 217434\n","[LightGBM] [Info] Number of data points in the train set: 127999, number of used features: 4709\n","[LightGBM] [Info] Start training from score -5.430057\n","[LightGBM] [Info] Start training from score -2.148851\n","[LightGBM] [Info] Start training from score -3.587613\n","[LightGBM] [Info] Start training from score -3.274695\n","[LightGBM] [Info] Start training from score -3.942958\n","[LightGBM] [Info] Start training from score -0.240045\n","[LightGBM] [Info] Start training from score -4.889724\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.704412 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217521\n","[LightGBM] [Info] Number of data points in the train set: 127999, number of used features: 4701\n","[LightGBM] [Info] Start training from score -5.430057\n","[LightGBM] [Info] Start training from score -2.148918\n","[LightGBM] [Info] Start training from score -3.587613\n","[LightGBM] [Info] Start training from score -3.274695\n","[LightGBM] [Info] Start training from score -3.942958\n","[LightGBM] [Info] Start training from score -0.240036\n","[LightGBM] [Info] Start training from score -4.889724\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.748645 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217497\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4703\n","[LightGBM] [Info] Start training from score -5.430049\n","[LightGBM] [Info] Start training from score -2.148910\n","[LightGBM] [Info] Start training from score -3.587888\n","[LightGBM] [Info] Start training from score -3.274480\n","[LightGBM] [Info] Start training from score -3.942950\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.889717\n","Classification Report for Fold 1:\n","              precision    recall  f1-score   support\n","\n","           0       0.32      0.07      0.12       140\n","           1       0.80      0.78      0.79      3732\n","           2       0.67      0.03      0.05       886\n","           3       0.69      0.07      0.12      1210\n","           4       0.67      0.03      0.05       620\n","           5       0.87      0.97      0.92     25171\n","           6       0.31      0.02      0.03       241\n","\n","    accuracy                           0.86     32000\n","   macro avg       0.62      0.28      0.30     32000\n","weighted avg       0.84      0.86      0.82     32000\n","\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.716339 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217559\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4705\n","[LightGBM] [Info] Start training from score -5.431833\n","[LightGBM] [Info] Start training from score -2.148910\n","[LightGBM] [Info] Start training from score -3.587605\n","[LightGBM] [Info] Start training from score -3.274480\n","[LightGBM] [Info] Start training from score -3.943353\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.888679\n","Classification Report for Fold 2:\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.07      0.12       141\n","           1       0.79      0.77      0.78      3732\n","           2       0.53      0.02      0.04       885\n","           3       0.63      0.06      0.11      1210\n","           4       0.69      0.02      0.03       621\n","           5       0.87      0.97      0.92     25171\n","           6       0.26      0.02      0.04       240\n","\n","    accuracy                           0.86     32000\n","   macro avg       0.60      0.28      0.29     32000\n","weighted avg       0.83      0.86      0.82     32000\n","\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.727591 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217526\n","[LightGBM] [Info] Number of data points in the train set: 127998, number of used features: 4711\n","[LightGBM] [Info] Start training from score -5.430049\n","[LightGBM] [Info] Start training from score -2.148843\n","[LightGBM] [Info] Start training from score -3.587605\n","[LightGBM] [Info] Start training from score -3.274687\n","[LightGBM] [Info] Start training from score -3.943353\n","[LightGBM] [Info] Start training from score -0.240038\n","[LightGBM] [Info] Start training from score -4.889717\n","Classification Report for Fold 3:\n","              precision    recall  f1-score   support\n","\n","           0       0.29      0.04      0.07       140\n","           1       0.81      0.78      0.79      3731\n","           2       0.68      0.04      0.07       885\n","           3       0.69      0.08      0.14      1211\n","           4       0.67      0.01      0.03       621\n","           5       0.87      0.97      0.92     25171\n","           6       0.17      0.01      0.02       241\n","\n","    accuracy                           0.86     32000\n","   macro avg       0.59      0.28      0.29     32000\n","weighted avg       0.84      0.86      0.82     32000\n","\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.743055 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 217434\n","[LightGBM] [Info] Number of data points in the train set: 127999, number of used features: 4709\n","[LightGBM] [Info] Start training from score -5.430057\n","[LightGBM] [Info] Start training from score -2.148851\n","[LightGBM] [Info] Start training from score -3.587613\n","[LightGBM] [Info] Start training from score -3.274695\n","[LightGBM] [Info] Start training from score -3.942958\n","[LightGBM] [Info] Start training from score -0.240045\n","[LightGBM] [Info] Start training from score -4.889724\n","Classification Report for Fold 4:\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.09      0.14       140\n","           1       0.81      0.78      0.79      3731\n","           2       0.69      0.03      0.06       885\n","           3       0.59      0.05      0.10      1211\n","           4       0.71      0.01      0.02       620\n","           5       0.87      0.97      0.92     25171\n","           6       0.25      0.01      0.02       241\n","\n","    accuracy                           0.86     31999\n","   macro avg       0.62      0.28      0.29     31999\n","weighted avg       0.84      0.86      0.82     31999\n","\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.139061 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 217521\n","[LightGBM] [Info] Number of data points in the train set: 127999, number of used features: 4701\n","[LightGBM] [Info] Start training from score -5.430057\n","[LightGBM] [Info] Start training from score -2.148918\n","[LightGBM] [Info] Start training from score -3.587613\n","[LightGBM] [Info] Start training from score -3.274695\n","[LightGBM] [Info] Start training from score -3.942958\n","[LightGBM] [Info] Start training from score -0.240036\n","[LightGBM] [Info] Start training from score -4.889724\n","Classification Report for Fold 5:\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.11      0.18       140\n","           1       0.80      0.78      0.79      3732\n","           2       0.71      0.03      0.06       885\n","           3       0.67      0.06      0.12      1211\n","           4       0.75      0.01      0.03       620\n","           5       0.87      0.97      0.92     25170\n","           6       0.57      0.02      0.03       241\n","\n","    accuracy                           0.86     31999\n","   macro avg       0.70      0.28      0.30     31999\n","weighted avg       0.84      0.86      0.82     31999\n","\n"]}],"source":["\n","# LightGBM model\n","model = lgb.LGBMClassifier(n_jobs=-1)\n","\n","# Stratified 5-fold cross-validation\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","predictions = cross_val_predict(model, X_tfidf, y_encoded, cv=cv)\n","\n","# Print classification report for each fold\n","for i, (train_index, test_index) in enumerate(cv.split(X_tfidf, y_encoded)):\n","    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n","    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n","\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    print(f\"Classification Report for Fold {i + 1}:\")\n","    print(classification_report(y_test, y_pred))\n","\n","# Overall classification report\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1069,"status":"ok","timestamp":1717354067620,"user":{"displayName":"Ayhan Öner","userId":"02527438790910619741"},"user_tz":-180},"id":"GfRrRxsIR2PW","outputId":"f7dbf48a-763c-492c-cdf2-9c5fc506fec5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overall Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.28      0.04      0.07       701\n","           1       0.80      0.78      0.79     18658\n","           2       0.65      0.02      0.05      4426\n","           3       0.72      0.06      0.12      6053\n","           4       0.59      0.01      0.03      3102\n","           5       0.87      0.97      0.92    125854\n","           6       0.21      0.01      0.03      1204\n","\n","    accuracy                           0.86    159998\n","   macro avg       0.59      0.27      0.28    159998\n","weighted avg       0.84      0.86      0.82    159998\n","\n"]}],"source":["print(\"Overall Classification Report:\")\n","print(classification_report(y_encoded, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qoFO7y4A7D5I"},"outputs":[],"source":["# Train the final model on the full training set and predict on the test set\n","model.fit(X_tfidf, y)\n","test_tfidf = tfidf.transform(test_data['summary'])\n","test_predictions = model.predict(test_tfidf)\n","\n","# Save the test predictions with mapping back to original severity strings\n","test_data['severity_mapped'] = test_predictions\n","test_data['severity'] = le.inverse_transform(test_data['severity_mapped'])\n","\n","test_data.rename(columns={\"bug id\": \"bug_id\"}, inplace=True)\n","output_data = test_data[['bug_id', 'severity']]\n","output_file_path = 'lgb_predictions_2.csv'\n","output_data.to_csv(output_file_path, index=False)\n","\n","print(f\"Predictions saved to {output_file_path}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMVz52dYhmkyNLZrn+OJTCF","gpuType":"L4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}